{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento para identificar la tipología fotográfica\n",
    "![Tipologías fotograficas](imagenes/tipologias.jpg)\n",
    "\n",
    "Este cuaderno se basa en la técnica de re entrenamiento o transferencia de aprendizaje y se realizó siguiendo las instrucciones del repositorio [Tensorflow for poets](https://github.com/googlecodelabs/tensorflow-for-poets-2) en la versión adaptada por Tim Sherrat en sus colleción [Glam Workbench] (https://github.com/GLAM-Workbench/image-recognition) Se usa una Red Neuronal Convolucional llamada MobileNet para crear un modelo que permite clasificar imagenes de acuerdo a su tipología fotográfica.\n",
    "\n",
    "NOTAS.\n",
    "- Originalmente este cuaderno lo trabajé en el sistema operativo linux por lo que algunos comandos son los de ese ambiente. \n",
    "- Las celdas que empiezan con los simbolos ! o $$ se ejecutan fuera del cuaderno jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Se debe descargar el repositorio que contiene los scripts para el re entrenamiento. Las imagenes que se usarán las obtendremos independientemente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/googlecodelabs/tensorflow-for-poets-2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que el cuaderno tenga acceso a la version 1.11.0 del modulo Tensorflow. Esta es una versión muy vieja por lo que hay que ser cuidadosos al crear en environment de Python para obtener la versión que necesitamos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accedemos al directorio que se acaba de descargar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd tensorflow-for-poets-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd #Muestra el directorio actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorias de entrenamiento\n",
    "\n",
    "Dentro de la carpeta tf_files bebemos copiar nuestras fotografías, para cada categorìa de clasificación usaremos un folder diferente y todos ellos deben estar en la carpeta training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls tf_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re entrenamiento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ejecuta el archivo retrain.py de la carpeta scripts que agrega una nueva capa final a la red y realiza el re entrenamiento. \n",
    "![convolución](imagenes/convolucion.jpg)\n",
    "\n",
    "Pero antes de hacerlo se definen variables para el tamaño de imagen (128,160,192, or 224px) y la arquitectura y tamaño de la red (1.0, 0.75, 0.50, or 0.25.). También se pasan otros parametros con los simbolos -- Como son varias lineas, se usan saltos de linea con \\ para mayor claridad.\n",
    "\n",
    "Si se omite la variable para la arquitectura de la red neuronal se usara por default la red Inception V3, sin embargo en este cuaderno se usa la red Mobilenet que es más pequeña y eficiente, aunque tambien menos precisa. Ambas redes han sido entrenadas con el conjunto de datos Imagenet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "IMAGE_SIZE=224\n",
    "ARCHITECTURE=\"mobilenet_0.50_${IMAGE_SIZE}\"\n",
    "\n",
    "python -m scripts.retrain \\\n",
    "  --bottleneck_dir=tf_files/bottlenecks \\\n",
    "  --how_many_training_steps=500 \\\n",
    "  --model_dir=tf_files/models/ \\\n",
    "  --summaries_dir=tf_files/training_summaries/\"${ARCHITECTURE}\" \\\n",
    "  --output_graph=tf_files/retrained_graph.pb \\\n",
    "  --output_labels=tf_files/retrained_labels.txt \\\n",
    "  --architecture=\"${ARCHITECTURE}\" \\\n",
    "  --image_dir=tf_files/training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al final el script produce dos archivos nuevos\n",
    "\n",
    "    - tf_files/retrained_graph.pb, la nueva red que hemos re entrenado\n",
    "    - tf_files/retrained_labels.txt, el archivo de texto con las categorias en las que dividimos las fotos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de clasificación \n",
    "\n",
    "Primero con una fotografía al azar del conjunto de entrenamiento tf_files/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of all the train images\n",
    "import os\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "imgs = []\n",
    "data_dir = 'tf_files/training'\n",
    "for img_dir in [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]:\n",
    "    for img in [i for i in os.listdir(os.path.join(data_dir, img_dir)) if i[-4:] == '.jpg']:\n",
    "        imgs.append(os.path.join(data_dir, img_dir, img))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one image at random\n",
    "img = random.sample(imgs, 1)[0]\n",
    "display(HTML('<img src=\"tensorflow-for-poets-2/{0}\" width=\"50%\" height=\"50%\"><br>{0}'.format(img)))\n",
    "print(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ejecuta el archivo llamado label_image, ubicado en la carpeta scripts, \n",
    "usando el nuevo modelo y el nuevo archivo de etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m scripts.label_image --graph=tf_files/retrained_graph.pb --labels=tf_files/retrained_labels.txt --image=$img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego con una fotografía que el sistema no conoce de la carpeta tf_files/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of all the test images\n",
    "import os\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "imgs = []\n",
    "data_dir = 'tf_files/testing'\n",
    "for img_dir in [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]:\n",
    "    for img in [i for i in os.listdir(os.path.join(data_dir, img_dir)) if i[-4:] == '.jpg']:\n",
    "        imgs.append(os.path.join(data_dir, img_dir, img))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one image at random\n",
    "img = random.sample(imgs, 1)[0]\n",
    "display(HTML('<img src=\"tensorflow-for-poets-2/{0}\" width=\"50%\" height=\"50%\"><br>{0}'.format(img)))\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m scripts.label_image --graph=tf_files/retrained_graph.pb --labels=tf_files/retrained_labels.txt --image=$img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagen de nuestra elección\n",
    "Solo debemos copiar la ruta de carpetas y el nombre del archivo que queremos clasificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= \"tf_files/testing/Impresion/STUDY152.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML('<img src=\"tensorflow-for-poets-2/{0}\" width=\"50%\" height=\"50%\"><br>{0}'.format(img)))\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m scripts.label_image --graph=tf_files/retrained_graph.pb --labels=tf_files/retrained_labels.txt --image=$img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glam_image_recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b44d613882dcce89f4f7a17effcc7de55d99d78686dd9a9c1c6131fc4d9634e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
